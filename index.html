<script src="http://www.google.com/jsapi" type="text/javascript"></script> 
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
	body {
		font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif; 
		font-weight:300;
		font-size:18px;
		margin-left: auto;
		margin-right: auto;
		width: 1100px;
	}
	
	h1 {
		font-size:32px;
		font-weight:300;
	}
	
	.disclaimerbox {
		background-color: #eee;		
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
		padding: 20px;
	}

	video.header-vid {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	img.header-img {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	img.rounded {
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	a:link,a:visited
	{
		color: #1367a7;
		text-decoration: none;
	}
	a:hover {
		color: #208799;
	}
	
	td.dl-link {
		height: 160px;
		text-align: center;
		font-size: 22px;
	}
	
	.layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		        0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		        5px 5px 0 0px #fff, /* The second layer */
		        5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		        10px 10px 0 0px #fff, /* The third layer */
		        10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
		        15px 15px 0 0px #fff, /* The fourth layer */
		        15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
		        20px 20px 0 0px #fff, /* The fifth layer */
		        20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
		        25px 25px 0 0px #fff, /* The fifth layer */
		        25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
		margin-left: 10px;
		margin-right: 45px;
	}

	.paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		        0px 0px 1px 1px rgba(0,0,0,0.35); /* The top layer shadow */

		margin-left: 10px;
		margin-right: 45px;
	}


	.layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		        0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		        5px 5px 0 0px #fff, /* The second layer */
		        5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		        10px 10px 0 0px #fff, /* The third layer */
		        10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
		margin-top: 5px;
		margin-left: 10px;
		margin-right: 30px;
		margin-bottom: 5px;
	}
	
	.vert-cent {
		position: relative;
	    top: 50%;
	    transform: translateY(-50%);
	}
	
	hr
	{
		border: 0;
		height: 1px;
		background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
	}
</style>

<html>
  <head>
		<title>PT4AL: Using Self-Supervised Pretext Tasks for Active Learning</title>
  </head>

  <body>
    <br>
          <center>
          	<span style="font-size:32px">PT4AL: Using Self-Supervised Pretext Tasks for Active Learning (ECCV 2022)</span>
	  		  <table align=center width=650px>
	  			  <tr>
	  	              <td align=center>
	  					<center>
	  						<span style="font-size:20px"><a href="https://johnsk95.github.io/">John Seon Keun Yi</a></span>&nbsp;&nbsp;&nbsp;&nbsp;
	  						<span style="font-size:20px"><a href="https://sites.google.com/view/minseokcv/">Minseok Seo</a></span>&nbsp;&nbsp;&nbsp;&nbsp;
	  						<span style="font-size:20px"><a href="https://sites.google.com/view/jongchanpark">Jongchan Park</a></span>&nbsp;&nbsp;&nbsp;&nbsp;
	  						<span style="font-size:20px"><a href="https://sites.google.com/site/dgchoicv/">Dong-Geol Choi</a></span>
		  		  		</center>
		  		  	  </td>
		  		  </tr>
	  			  <tr>
		  		  </tr>
			  </table>
	  		  <table align=center width=600px>
	  			  <tr>
	              <td align=center width=120px>
	  					<center>
	  						<span style="font-size:24px"><a href='https://arxiv.org/abs/2201.07459'>[Paper]</a></span>
		  		  		</center>
		  		  	  </td>
	              <td align=center width=120px>
	  					<center>
	  						<span style="font-size:24px"><a href='https://github.com/johnsk95/PT4AL'>[Code]</a></span><br>
		  		  		</center>
		  		  	  </td>
	  	              <td align=center width=120px>
	  					<center>
	  						<span style="font-size:24px"><a href='https://www.youtube.com/watch?v=SN7U13MMbOk'>[Video]</a></span><br>
		  		  		</center>
		  		  	  </td>
	  			  <tr>
			  </table>
          </center>

          <center>
  		  <table align=center width=850px>
  			  <tr>
  	              <td width=500px>
  					<center>
  	                	<img class="round" style="width:900px;" src="pt4al_main.png"/>
	  				</center>
  	              </td>  	              
                </tr>
  		  </table>  		  
  		</center>

          <hr>

  		  <table align=center width=875px>
	  		  <center><h1>Abstract</h1></center>
	  		  <tr>
	  		  	<td><p>
					Labeling a large set of data is expensive. Active learning aims to tackle this problem by asking to annotate only the most informative data from the unlabeled set. We propose a novel active learning approach that utilizes self-supervised pretext tasks and a unique data sampler to select data that are both difficult and representative. We discover that the loss of a simple self-supervised pretext task, such as rotation prediction, is closely correlated to the downstream task loss. Before the active learning iterations, the pretext task learner is trained on the unlabeled set, and the unlabeled data are sorted and split into batches by their pretext task losses. In each active learning iteration, the main task model is used to sample the most uncertain data in a batch to be annotated. We evaluate our method on various image classification and segmentation benchmarks and achieve compelling performances on CIFAR10, Caltech-101, ImageNet, and Cityscapes. We further show that our method performs well on imbalanced datasets, and can be an effective solution to the cold-start problem where active learning performance is affected by the randomly sampled initial labeled set. Code is available at <a>https://github.com/johnsk95/PT4AL</a>.
					</p>
	  		    </td>
	  		  </tr>
			</table>
  		  <br>
		  <hr>
			
		<table align=center width=490px>
	 		<center><h1>Paper and Supplementary Material</h1></center>
  			  <tr>
				  <td><a href="https://arxiv.org/abs/2201.07459"><img class="layered-paper-big" style="height:175px" src="paper_image.png"/></a></td>
				  <td><span style="font-size:14pt">Yi, J. S. K., Seo, M., Park, J., & Choi, D. G.<br>
				  <b>PT4AL: Using Self-Supervised Pretext Tasks for Active Learning</b><br>
				  (hosted on <a href="https://arxiv.org/abs/2201.07459">ArXiv</a>)<br>
				  <span style="font-size:4pt"><a href=""><br></a>
				  </span>
				  </td>
  	              </td>
              </tr>
  		  </table>
		  <br>

		  <table align=center width=600px>
			  <tr>
				  <td><span style="font-size:14pt"><center>
				  	<a href="./assets/bibtex_sentry.txt">[Bibtex]</a>
  	              </center></td>
              </tr>
  		  </table>

  		  <hr>

  		  <table align=center width=700px>
	  		  <center><h1>Method overview</h1></center>
  			  <tr>
  	              <td align=center width=700px>
  					<center>
						  <td><img class="round" style="width:800px" src="./assets/sentry.gif"/></td>
	  		  		</center>
			  </tr>
		  </center>
		  </table>
		  <br>
		  <hr>
        <!-- <center><h1>Video</h1></center>
        <p align="center">
		<iframe id="video" width="660" height="395" src="https://drive.google.com/file/d/1mkBGtHmq1hq-SQSoKptHbr5BF_lyZIGP/preview" frameborder="0" allow="autoplay;" allowfullscreen align="center"></iframe></p>
  		  <table align=center width=800px>
			  <br>
			  <tr><center>
				<span style="font-size:28px">&nbsp;<a href='https://drive.google.com/file/d/1b5vOPMmKHWmLr2eYza3CZEELYcKakExj/view?usp=sharing'>[Slides]</a>
		  </table>
        <hr>
 -->
 		<center><h1>Code</h1></center>

  		  <table align=center width=700px>
<!-- 		  	<center>
		  		<tr>
		  			<td>
		  				<b>Results on DomainNet Classification</b>
		  			</td>
		  		</tr>
		  </center> -->
		  </table>
  		  <table align=center width=700px>
  			  <tr>
  	              <td align=center width=700px>
  					<center>
						  <td><img class="round" style="width:700px" src="./assets/results.png"/></td>
	  		  		</center>
			  </tr>
		  </table>
  		  <table align=center width=800px>
			  <br>
			  <tr><center>
				<span style="font-size:28px">&nbsp;<a href='https://github.com/johnsk95/PT4AL'>[GitHub]</a>
		  </table>

      	  <br>
		  <hr>
		<br>
		  <!-- <hr> -->
        <center><h1>Video</h1></center>
        <p align="center">
		<iframe width="560" height="315" src="https://www.youtube.com/embed/SN7U13MMbOk" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></p>

  		  <table align=center width=800px>
			  <br>
			  <tr><center>
              
</body>
</html>
